{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf4e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tqdm\n",
    "import ijson\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0614e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113689it [01:38, 1149.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-456b60bacc65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dblp.v12.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mijson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"item\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ijson/common.py\u001b[0m in \u001b[0;36mitems\u001b[0;34m(prefixed_events, prefix, map_type)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefixed_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'start_map'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ijson/common.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(basic_events)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'start_map'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end_map'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "authors = []\n",
    "papers = []\n",
    "conferences = []\n",
    "journals = []\n",
    "keywords = []\n",
    "cites = []\n",
    "\n",
    "with open(\"dblp.v12.json\", \"rb\") as f:\n",
    "\n",
    "    #iterate over each paper\n",
    "    for i, element in tqdm.tqdm(enumerate(ijson.items(f, \"item\"))):\n",
    "        try:\n",
    "            p_id = element[\"id\"]\n",
    "            p_title = element[\"title\"]\n",
    "            p_year = element.get(\"year\")\n",
    "            \n",
    "            conf_title = \"\"\n",
    "            jour_title = \"\"\n",
    "            conf_id = \"\"\n",
    "            jour_id = \"\"\n",
    "            edition = 0\n",
    "\n",
    "            #skip paper if year of publication not available\n",
    "            if not p_year:\n",
    "                continue\n",
    "\n",
    "            #skip paper if n_citation or page information not available\n",
    "            if (\"n_citation\" not in element) or (\"page_start\" not in element) or (\"page_end\" not in element):\n",
    "                continue\n",
    "\n",
    "            p_pages = element[\"page_start\"] + \"-\" + element[\"page_end\"]\n",
    "\n",
    "            #skip paper if abstract not available\n",
    "            if \"indexed_abstract\" not in element:\n",
    "                continue\n",
    "\n",
    "            p_abstract = ' '.join(list(element[\"indexed_abstract\"][\"InvertedIndex\"].keys()))\n",
    "\n",
    "            #skip paper if authors not given\n",
    "            if \"authors\" not in element:\n",
    "                continue\n",
    "\n",
    "            #skip paper if organization of author not available\n",
    "            org = True\n",
    "            for n in element['authors']:\n",
    "                if \"org\" not in n:\n",
    "                    org = False\n",
    "            if org == False:\n",
    "                continue\n",
    "\n",
    "            #skip paper if field of study is not available\n",
    "            if \"fos\" not in element:\n",
    "                continue\n",
    "\n",
    "            #skip paper if reference is not available\n",
    "            if \"references\" not in element:\n",
    "                continue\n",
    "\n",
    "            if \"type\" in element[\"venue\"]:\n",
    "                #for each paper get conference with title and edition\n",
    "                if element[\"venue\"][\"type\"] == \"C\":\n",
    "                    element[\"volume\"] = element[\"volume\"].strip()\n",
    "                    if \"venue\" in element and \"type\" in element[\"venue\"] and element[\"volume\"] != '':\n",
    "                            conf_title = element[\"venue\"][\"raw\"]\n",
    "                            edition = int(element[\"volume\"])\n",
    "                            conf_id = element[\"venue\"][\"id\"]          \n",
    "                    else:\n",
    "                        #skip paper if any of conference information is missing\n",
    "                        continue\n",
    "\n",
    "                #for each paper get journal with title and volume\n",
    "                elif element[\"venue\"][\"type\"] == \"J\":\n",
    "                    element[\"volume\"] = element[\"volume\"].strip()\n",
    "                    if \"venue\" in element and \"type\" in element[\"venue\"] and element[\"volume\"] != '':\n",
    "                            jour_title = element[\"venue\"][\"raw\"]\n",
    "                            edition = int(element[\"volume\"])\n",
    "                            jour_id = element[\"venue\"][\"id\"]\n",
    "                    else:\n",
    "                        #skip paper if any of journal information is missing\n",
    "                        continue\n",
    "            else:\n",
    "                #skip paper if venue information is missing\n",
    "                continue\n",
    "\n",
    "            papers.append((p_id, p_title, p_year, element[\"n_citation\"], p_pages, p_abstract))\n",
    "            authors.extend([(p_id, n['name'], n['org'], n['id']) for n in element['authors']])\n",
    "            keywords.extend([(p_id, n['name']) for n in element['fos']])\n",
    "            cites.extend([(n, p_id) for n in element['references']])\n",
    "            conferences.append((p_id, conf_title, edition, p_year, conf_id))\n",
    "            journals.append((p_id, jour_title, edition, p_year, jour_id))\n",
    "        \n",
    "        except:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c91b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframes\n",
    "paper_df = pd.DataFrame(papers, columns=['paper_id','title', 'year', 'n_citations', 'pages', 'abstract'])\n",
    "author_df = pd.DataFrame(authors, columns=['paper_id', 'name', 'organization', 'author_id'])\n",
    "conf_df = pd.DataFrame(conferences, columns=['paper_id', 'name','edition','year','conference_id'])\n",
    "jour_df = pd.DataFrame(journals, columns=['paper_id', 'name','volume','year','journal_id'])\n",
    "key_df = pd.DataFrame(keywords, columns=['paper_id', 'keyword'])\n",
    "cite_df = pd.DataFrame(cites, columns=['paper_id', 'cited_by'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40014c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process dataframes to make required csv files\n",
    "paper_df.to_csv(\"data/papers.csv\", index=False)\n",
    "conf_df.drop_duplicates(subset=['paper_id','conference_id']).to_csv('data/paper_published_in_conference.csv', index=False)\n",
    "jour_df.drop_duplicates(subset=['paper_id','journal_id']).to_csv('data/paper_published_in_journal.csv', index=False)\n",
    "author_df.drop_duplicates(subset=['paper_id','author_id']).to_csv('data/paper_written_by_author.csv', index=False)\n",
    "author_df[['author_id', 'name','organization']].drop_duplicates(subset=['author_id']).to_csv('data/authors.csv', index=False)\n",
    "conf_df[['conference_id','name', 'edition', 'year']].drop_duplicates(subset=['conference_id']).to_csv('data/conference.csv', index=False)\n",
    "jour_df[['journal_id','name', 'volume', 'year']].drop_duplicates(subset=['journal_id']).to_csv('data/journal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkey_df = key_df[['keyword']].drop_duplicates()\n",
    "tkey_df['keyword_id'] = tkey_df.index+1\n",
    "tkey_df[['keyword_id','keyword']].to_csv('data/keywords.csv', index=False)\n",
    "key_df.merge(tkey_df, on='keyword')[['paper_id','keyword_id']].to_csv('data/paper_has_keywords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_df[cite_df.paper_id.isin(cite_df.cited_by.unique())].to_csv('data/paper_cited_paper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895335c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e62a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
